{
  "hash": "575ce0ef77096498797fcc63ed5635ad",
  "result": {
    "engine": "knitr",
    "markdown": "---\nengine: knitr\n---\n\n\n\n\n\n# Causality {#sec-week3}\n\n**Last updated:** 16 Sep\\, 2024 01:46 AM EDT\n\n## Introduction\n\nCausality and causal inference is a broad area that covers applications in\nbiomedical research, epidemiology, economics, sociology, law and others. It also\nencompasses aspects of statistics and philosophy, driven by the context within\nwhich causality is being investigated.\n\nCausality is not a concept that is necessarily clear-cut in its evaluation. Two\nindividuals have heavy influence in this field: [Judea\nPearl](https://en.wikipedia.org/wiki/Judea_Pearl), a computer scientist and\nphilosopher at UCLA and [Donald\nRubin](https://en.wikipedia.org/wiki/Donald_Rubin), a statistician at Harvard\nUniversity. Rubin promoted a \"potential outcomes framework\" for the statistical\nevaluation of causality, which has been furthered by the work of [Miguel\nHernan](https://www.hsph.harvard.edu/miguel-hernan/), a biostatistician at\nHarvard University. Pearl, on the other hand, promoted the idea that causality\ncannot be evaluated purely from data and empirical approaches but requires an\nunderstanding of context. He developed *causal diagrams* and the utility of\n*Bayesian networks* as a means to make probabilistic evaluations of causality.\nWe will use both frameworks to explore this topic, and see how to consider\ncausality within the biomedical realm. This objective is stated by both Pearl\nand Rubin in their works\n\n> This chapter, and the following one, is based on several reference works:\n>\n> -   [*The Book of\n>     Why*](https://www.hachettebookgroup.com/titles/judea-pearl/the-book-of-why/9781541698963/?lens=basic-books){target=\"_blank\"}\n>     by Judea Pearl and Dana Mackenzie\n>\n> -   [*Causal Inference for Statistics, Social, and Biomedical Sciences: An\n>     Introduction*](https://www.cambridge.org/core/books/causal-inference-for-statistics-social-and-biomedical-sciences/71126BE90C58F1A431FE9B2DD07938AB){target=\"_blank\"}\n>     by Guido W. Imbens and Donald B. Rubin\n>\n> -   [Causal Inference: What\n>     If](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/){target=\"_blank\"}\n>     by Miguel A. Hernan and James M. Robins\n>\n> -   [Causal Inference in R](https://www.r-causal.org){target=\"_blank\"} by\n>     Malcolm Barrett, Lucy D'Agostino McGowan and Travis Gerke\n>\n> as well as other papers and examples.\n\n## What are we trying to do?\n\nWe are primarily interested in **causal statements and questions** of the nature\n\n-   Smoking causes lung cancer\n\n-   How effective is a treatment in prolonging life among lung cancer patients?\n\n-   What is the healthcare cost *attributable* to the increasing prevalence of\n    obesity?\n\n-   Can scheduling records and hospital interactions prove someone is guilty of\n    medical malpractice?\n\n-   Can a drug that targets the activity of a particular biological functional\n    pathway cause a disease to be cured by the drug?\n\nWe can think through many more, across different fields.\n\nData, particular Big Data, appear to be attractive means to evaluate such\nstatements. Surely, as we collect more data, we should be able to ascertain\nwhether a drug can cure disease, or whether using Ozempic will reduce weight, or\nthat eating less red meat will prolong our lives.\n\nStatistical approaches try to find patterns in data beyond what might be caused\nby randomness or measurement errors. This is leveraged heavily to try and assess\nwhether there is some relationship, or **association** between some treatment or\nexperience (generally denoted an *exposure*) and the eventual *outcome* we want\nto study. Similarly, supervised machine learning tries to use different features\nin a data corpus to predict an outcome. Both leverage observed patterns of\ncorrelation or association between the features (covariates) and the outcome to\ndo so. A lot of effort also goes into improving predictions or modeled\nassociations by (a) experimental design, (b) adding more independent features to\nimprove the precision of the prediction or association.\n\nThese modeling efforts really are leveraging the **observed** association\nbetween features and the outcome. This observed association is often subject to\nmany other factors, including **biases** in subject selection and data\ncollection, presence of related factors both observed and unobserved that can\ninfluence the observed association, and measurement error. We saw\n[earlier](week-02.qmd#sec-dewey) how the observed data might lead to wrong\ninferences, or at the very least, reporting spurious associations. This leads to\nthe oft-quoted aphorism in statistics that \"correlation does not mean\ncausation\", but often no clear counter as to what would show causation.\n\n::: callout-note\n## What is an \"association\"?\n\nWe often use the term **association** in this text and other textbooks and\npapers. What do we mean as statisticians? The term is often used to say that two\nvariables have *a relationship*, in that there is some pattern between the\nvalues of the two variables. What we often tacitly imply in using the term is\n**correlation**, in that high values of one variable appear to co-occur on\naverage with high values of the other variable (positive correlation), or low\nvalues of the other variable (negative correlation). Note, I specifically use\nthe term \"co-occur\", because that's really all we can determine in observational\ndata.\n\nJust because observational values co-occur doesn't mean that one caused the\nother. There are plenty of examples of [spurious\ncorrelations](https://www.tylervigen.com/spurious-correlations) and [ecological\nfallacies](https://en.wikipedia.org/wiki/Ecological_fallacy) where there is no\nactual causal relationship between the variables, while we observe a high degree\nof association between them.\n:::\n\nHowever, the word \"association\" is often tacitly associated with causal intent\nwhen it is used, instead of being explicit\n\n> \"Our results suggest that 'Schrödinger’s causal inference,' — where studies\n> avoid stating (or even explicitly deny) an interest in estimating causal\n> effects yet are otherwise embedded with causal intent, inference,\n> implications, and recommendations — is common.\" [Haber, N. A., S. E. Wieten,\n> J. M. Rohrer, O. A. Arah, P. W. G. Tennant, E. A. Stuart, E. J. Murray, et al.\n> 2022. “Causal and Associational Language in Observational Health Research: A\n> Systematic Evaluation.” Am J Epidemiol 191 (12): 2084–97.]{.aside}\n\nSo, if we can only look at observed data and associations between variables, how\ndo we go further? What we would like to know in many occasions is, whether an\nexposure **caused** disease. Not just an association, but a causation. A higher,\nstronger standard of evidence. That is the goal of the rhetorical question we\nstarted with.\n\nToday, we generally accept that \"smoking causes lung cancer\". However, not all\nsmokers get lung cancer, and not all lung cancer patients are smokers. But yet,\nwe think we have sufficient evidence to *infer* a causal link. What evidence\ngets us to this inference?\n\n## Three objectives of data scientific investigation\n\nWe typically have one of three objectives in data scientific investigations:\n\nDescriptive\n\n:   Description of patterns in the data in order to gain insights into\n    inter-relationships between different measured variables. This provides a\n    sense of associations, patterns, and outliers. Examples include describing\n    patterns of infant mortality over time and geography, fitting a polynomial\n    line to a scatter plot of cholesterol levels at 40 years old with age at\n    death, looking for patterns in gene expression that are different between\n    ER/PR positive and HER2 positive and triple-negative breast cancer tumors.\n    Think back to John Snow's cholera analysis.\n\nPredictive\n\n:   Predicting a categorical or quantitative state from other measured features.\n    Machine learners and computer scientists see this as their main objective\n    for data science, and we know of widespread use of such investigations in\n    finance, advertising, marketing and other domains. In biomedical science, we\n    also do use predictive modeling; for example, predicting a woman's lifetime\n    risk of getting breast cancer, predicting cell types from transcriptomic\n    data in single-cell experiments, predicting adult height from childhood\n    growth patterns.\n\nExplanation\n\n:   Observing an outcome and trying to explain what other measured factors might\n    be implicated in causing or influencing that outcome. In biomedical science,\n    this is the main question of interest. The idea being that, if we can figure\n    out the \"why\" of disease development, we can get to the \"how\" of preventing\n    or curing it. If we find that a set of genes is implicated in developing\n    cystic fibrosis, we might pay more attention to individuals with that\n    genetic profile. If we can figure out genetic profiles for different kinds\n    of breast cancer, we can target those profiles with different drugs\n    (tamoxifen for ER/PR+ breast cancer, herceptin/Enhertu for HER2+ breast\n    cancer, for example); or, if we find a genetic profile common to the\n    development of multiple cancers, we have the potential to target multiple\n    cancers with the same drug (Merck's Keytruda PD-L1 immune checkpoint\n    inhibitor that has proven effective in multiple cancers, given a common\n    implication of increased PD-L1 expression in many cancers)\n\n::: callout-important\n## One model, different objectives\n\nMost supervised learning methods, including something as basic as linear\nregression, can be used to achieve all three objectives. but they are approached\nand fit differently.\n\nLet's consider linear regression:\n\n1.  You can fit a linear or polynomial model to a scatter plot to summarise\n    patterns in the data\n2.  You can use it to predict length of stay in a hospital based on intake\n    department, season, insurance status, age, gender and race. This process\n    typically uses (stochastic) gradient descent for fitting and\n    cross-validation to identify robustness and generalizability of the class of\n    models we are fitting.\n3.  You can use it to ask to what extent intake department influences length of\n    hospital stay, i.e. how does different conditions present on admission\n    affect how long a patient stays, at least on average. Here, we start\n    thinking about causal relationships, proper adjustment in a multivariate\n    model, confounding and other biases. We usually fit these models (as a\n    statistician would) using the usual closed-form methods. Why is this\n    interesting? If we can identify that the relationship between intake\n    department and length of stay is *causal*, we can then try to optimize\n    conditions in departments with higher lengths of stay to improve the overall\n    hospital situation (Lower lengths of stay are desirable for hospitals)\n\nSo the same model has different purposes and different optimization approaches.\nThat's partly why it can be confusing.\n:::\n\nAn explainable objective gets us towards causal models, but not all the way\nthere. Issues around bias, confounding, and fairly accounting for potential\noutcomes (counterfactuals) come into play. You have to make assumptions in a\ncausal model that are sometimes not verifiable. But, nonetheless, the thought\nexperiment and process of getting to a reasonable causal model is important both\nfor statistically thinking about a question or problem, and making valid\ninference and decisions.\n\nWe can think about a hierarchy of causation, following Pearl (@fig-cause)\n\n![The Ladder of Causation, from *The Book of Why*, p.\n28](images/clipboard-1063284710.png){#fig-cause}\n\nWithin this hierarchy, \"machine learning programs (including those with deep\nneural networks) operate almost entirely in an associational mode\" (\n@pearl:2018, pp. 30). As we said above, supervised learning models are entirely\nbased on observable patterns and so can't necessarily identify causal\nrelationships, no matter how large the training data is. In particular,\nobserving that $\\Pr(Y | X) > \\Pr(Y)$ does not imply that X has a causal relation\nwith Y, since that increase in conditional probability can happen due to other\ncauses like confounders, as we will investigate later.\n\nInterventional causation cannot be assessed merely by collecting data. The more\nstraightforward methods include experimental design like randomized controlled\nstudies and A/B testing methods, which can generate balance in other factors and\nallows statistical estimation of the interventional effect. We can also approach\nthis problem using modeling approaches in observational studies, including\npropensity scoring that we will introduce in @sec-week4. Such causal models\nallow us to use observed data to make (a modicum of ) causal inferences.\n\nThe third run of this ladder links Pearl's ideas to Rubin's potential outcomes\nframework. It asks what could have happened if a different (unobservable) action\nwas experienced. We'll describe this more in the next section, but in the mean\ntime, understand that this idea cannot be directly evaluated using observable\ndata, since we can only observe the outcome that results from the action or\nexposure that was actually experienced, and other potential outcomes that might\nhave happened if different exposures were experienced cannot be part of the data\ncorpus. This is of course an area where machine learning has contributed some\nmore understanding, especially in the concept of [**digital\ntwins**](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-digital-twin-technology#){target=\"_blank\"}\n(also see @katsoulakis:2024) where we can model and simulate doppelgangers who\nmight exhibit different outcomes when experiencing different exposures, at least\n*in silico*.\n\n## Concept 1: Counterfactuals, or potential outcomes\n\nWe consider different related actions that can be performed on an experimental\nunit. For example, we can consider the actions {Take ibuprofen} and {Don't take\nibuprofen} as two actions that a person might take when experiencing a headache.\nEach action can then be associated with an outcome for that individual, e.g.\n\n| Action               | Outcome                      |\n|----------------------|------------------------------|\n| Take ibuprofen       | Headache resolves in 1 hour  |\n| Don't take ibuprofen | Headache resolves in 6 hours |\n\nThese are *potential outcomes* since we can only observe one of them depending\non what action was actually taken. This is a simple example with two potential\nactions, but this can be generalized to multiple potential outcomes.\n\nThe idea of counterfactuals is at the top rung of the Ladder of Causation, and\nit involves the kinds of questions that we **want** to answer, like, would a\npatient recover faster if I use a different kind of suture on a wound? This is\nalso the question we ask all the time in clinical trials:\n\n> Would a patient live longer if we give him a new drug instead of the current\n> standard of treatment?\n\nThe problem is that, we can never answer this question using data from the\nphysical world, since we only have one shot at giving a patient one of the two\ndrugs, and we can't physically know what would happen if we gave the other drug.\n\nNotationaly, consider a study with *n* experimental units denoted by\n$i = 1, \\dots, n$, Suppose we have a treatment (or exposure, or policy; the\nsemantics are contextual) that takes two levels *0* (no treatment) and *1*\n(treatment). We can then see two potential outcomes\n\n$$\nY_i(1) \\text{ and } Y_i(0)\n$$\n\nunder the treatments *0* and *1*. The **individual** causal effect (which is\nunobservable) is $Y_i(1) - Y_i(0)$. We could think of the following thought\nexperiment. We look at a population where we could look at all possible\noutcomes:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1020)\nlibrary(tidyverse)\nlibrary(gt)\ndat <- tibble(\n  id = 1:10,\n  headache_ibf = c(1,3,5,3,1,1,2,3,1,2),\n  headache_noibf = c(6,6,5,3,6,7,4,5,6,6)\n)\ndat <- dat |> \n  mutate(causal_effect = headache_ibf - headache_noibf)\n\ngt(dat) |> \n  cols_label(headache_ibf = \"{{Y_i}}(ibf)\",\n             headache_noibf = \"{{Y_i}}(no ibf)\",\n             causal_effect = html(\"Y<sub>i</sub>(ibf) - Y<sub>i</sub>(no ibf)\")\n  ) |> \n  tab_spanner(label = \"Potential outcomes\", columns = 2:3) |> \n  tab_spanner(label = \"Causal effect\", columns = 4) |> \n  cols_align(align='center')\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"prlpuqojaq\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#prlpuqojaq table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#prlpuqojaq thead, #prlpuqojaq tbody, #prlpuqojaq tfoot, #prlpuqojaq tr, #prlpuqojaq td, #prlpuqojaq th {\n  border-style: none;\n}\n\n#prlpuqojaq p {\n  margin: 0;\n  padding: 0;\n}\n\n#prlpuqojaq .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#prlpuqojaq .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#prlpuqojaq .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#prlpuqojaq .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#prlpuqojaq .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#prlpuqojaq .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#prlpuqojaq .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#prlpuqojaq .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#prlpuqojaq .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#prlpuqojaq .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#prlpuqojaq .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#prlpuqojaq .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#prlpuqojaq .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#prlpuqojaq .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#prlpuqojaq .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#prlpuqojaq .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#prlpuqojaq .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#prlpuqojaq .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#prlpuqojaq .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#prlpuqojaq .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#prlpuqojaq .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#prlpuqojaq .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#prlpuqojaq .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#prlpuqojaq .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#prlpuqojaq .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#prlpuqojaq .gt_left {\n  text-align: left;\n}\n\n#prlpuqojaq .gt_center {\n  text-align: center;\n}\n\n#prlpuqojaq .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#prlpuqojaq .gt_font_normal {\n  font-weight: normal;\n}\n\n#prlpuqojaq .gt_font_bold {\n  font-weight: bold;\n}\n\n#prlpuqojaq .gt_font_italic {\n  font-style: italic;\n}\n\n#prlpuqojaq .gt_super {\n  font-size: 65%;\n}\n\n#prlpuqojaq .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#prlpuqojaq .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#prlpuqojaq .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#prlpuqojaq .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#prlpuqojaq .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#prlpuqojaq .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#prlpuqojaq .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings gt_spanner_row\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"id\">id</th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Potential outcomes\">\n        <span class=\"gt_column_spanner\">Potential outcomes</span>\n      </th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Causal effect\">\n        <span class=\"gt_column_spanner\">Causal effect</span>\n      </th>\n    </tr>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Y&lt;span style=&quot;white-space:nowrap;&quot;&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;(ibf)\">Y<span style=\"white-space:nowrap;\"><sub>i</sub></span>(ibf)</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Y&lt;span style=&quot;white-space:nowrap;&quot;&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/span&gt;(no ibf)\">Y<span style=\"white-space:nowrap;\"><sub>i</sub></span>(no ibf)</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Y&lt;sub&gt;i&lt;/sub&gt;(ibf) - Y&lt;sub&gt;i&lt;/sub&gt;(no ibf)\">Y<sub>i</sub>(ibf) - Y<sub>i</sub>(no ibf)</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">1</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">1</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">6</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">-5</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">2</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">3</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">6</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">-3</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">3</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">5</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">5</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">4</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">3</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">3</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">0</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">5</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">1</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">6</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">-5</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">6</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">1</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">7</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">-6</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">7</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">2</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">4</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">-2</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">8</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">3</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">5</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">-2</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">9</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">1</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">6</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">-5</td></tr>\n    <tr><td headers=\"id\" class=\"gt_row gt_center\">10</td>\n<td headers=\"headache_ibf\" class=\"gt_row gt_center\">2</td>\n<td headers=\"headache_noibf\" class=\"gt_row gt_center\">6</td>\n<td headers=\"causal_effect\" class=\"gt_row gt_center\">-4</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\nIf we could actually see this, we see that the average causal effect was\n-3.2 . If we randomly assign people in this population\nto take ibuprofen or not, we would get\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1038)\ndata_observed <- dat |> \n  mutate(\n    exposure = ifelse(rbinom(n(),1, 0.5) == 1, 'ibf','no_ibf'),\n    observed_outcome = ifelse(exposure=='ibf', headache_ibf, headache_noibf)\n  ) |> \n  select(id, exposure, observed_outcome)\ndata_observed |> \n  group_by(exposure) |> \n  summarise(avg_outcome = mean(observed_outcome)) |> \n  pivot_wider(names_from = exposure, values_from = avg_outcome) |> \n  mutate(causal_effect = ibf - no_ibf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n    ibf no_ibf causal_effect\n  <dbl>  <dbl>         <dbl>\n1  2.57   5.67         -3.10\n```\n\n\n:::\n:::\n\n\n\n\n\n::: callout-tip\nSee what you would get if you didn't randomize the treatment allocation.\n:::\n\nOnce again, we'll return to ways of answering this question in @sec-week4.\n\n## Concept 2: Confounders, colliders and mediators\n\n-   Yule-Simpson Paradox\n\nConfounding bias is a central concern of causal inference. It occurs when a\nvariable influences both who is selected for treatment (or is exposed) and the\noutcome of the experiment. Confounders can be known (measured) or unknown\n(unmeasured). In a causal diagram, we can denote that *Z* is a confounder of the\nrelationship between *X* and *Y* if\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggdag)\ndagify(\n  Y ~ X + Z,\n  X ~ Z,\n  exposure = \"X\", outcome = \"Y\"\n) |> ggdag() + theme_dag()\n```\n\n::: {.cell-output-display}\n![](week-03_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThis diagram shows that there are two sources of association between *X* and\n*Y*. One is the path $X \\rightarrow Y$ which represents the causal effect of *X*\non *Y*, and the path $X \\leftarrow Z \\rightarrow Y$ which includes the common\ncause *Z*. This second path is an example of a *backdoor path*.\n\n::: callout-tip\n## A backdoor path\n\nA backdoor path is a noncausal path between treatment and outcome that remains\neven if all arrows pointing from the treatment to other variables are removed.\nThat is, the path has an arrow pointing into treatment. (@hernan:2023)\n:::\n\nConfounding, or rather, identifying confounders, can be approached using what is\ncalled the *backdoor criterion*.\n\n::: callout-tip\n## The backdoor criterion\n\nA set of covariates *Z* satisfies the backdoor criterion if all backdoor paths\nbetween *X* and *Y* are blocked by conditioning on *Z*, and *Z* contains no\nvariables that are descendants (i.e., flow from) the treatment *X*.\n(@hernan:2023)\n:::\n\nThe idea behind this backdoor criterion is, if we condition on values of\nvariables satisfing the backdoor criterion, then the spurious association\ngenerated by the confounder disappears. We can \"deconfound\" (@pearl:2018) the\neffect of the confounder by computing the effect of *X* on *Y* for every unique\nvalue of *Z* separately, and then take the weighted average of effects, with\nweights determined by the relative prevalence of different values of *Z*. To fix\nideas, if we consider our earlier ibuprofen example and consider *Z* to be age\ngroups, then we would compute the treatment effect within each age group, and\nthen take the average treatment effect weighted by the number of people in each\nage group. One way to statistically approach this is through *adjustment* for\nthe confounder in a regression model. This approach can be used in\nobservational, non-randomized studies, but there is a more principled approach\nwe will introduce in @sec-week4.\n\nThe concept of backdoor paths also tells us why random allocation of an exposure\nto subjects works to prevent confounding, a.k.a. the randomized controlled\ntrial. If you randomly allocate treatments/exposures to subjects, you break up\nany causal paths from other variables to the treatment, and hence prevent the\npresence of any backdoor paths. The only causal path to the outcome comes from\nthe randomly allocated treatment.\n\n### Other forks in the road: mediators and colliders\n\nWe can also consider the following two causal pathways and their implications on\nconditioning.\n\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\ndagify(\n  Z ~ X,\n  Y ~ Z\n) |> \n  ggdag(layout='circle') + theme_dag()\n```\n\n::: {.cell-output-display}\n![Mediator](week-03_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndagify(\n  Z ~ X,\n  Z ~ Y\n) |> \n  ggdag(layout='circle') + theme_dag()\n```\n\n::: {.cell-output-display}\n![Collider](week-03_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\n\n\n\nA mediator *modifies* the effect of *X* on *Y*, and if you decide to condition\non *Z* then you will remove the effect of *X* on *Y*.\n\nA collider is associated with both *X* and *Y*, but in a non-causal manner. *X*\nand *Y* are not causally related, but conditioning on *Z* *induces* a spurious\nassociation between *X* and *Y*.\n\nPearl describes rules that tell us how to stop the flow of information through\nany individual junction:\n\na.  In a chain junction $A \\rightarrow B \\rightarrow C$, controlling for *B*\n    prevents information from *A* from flowing to *C*\n\nb.  In a fork or confounding junction $A \\leftarrow B \\rightarrow C$,\n    controlling for B prevents information from *A* from flowing to *C* and vice\n    versa\n\nc.  In a collider $A \\rightarrow B \\leftarrow C$, A and C are independent, but\n    controlling for B makes information flow between A and C\n\nd.  Controlling for descendants (or proxies) of a variable is like \"partially\"\n    controlling for the variable itself, and so \"partially\" has the consequences\n    described above.\n\nThese ideas can inform what variables one **should** adjust for in a statistical\nmodel. Unfortunately there is a tendency to adjust for *all* potential\nconfounders, whether the causal diagram is investigated or not, and this can in\nitself lead to spurious associations. The causal diagrams help us understand\nwhat variables are potential confounders and so need to be adjusted for. Note\nhere that creating the causal diagram is **not statistical in nature** but\ndepends primarily on domain knowledge.\n\n#### Examples of confounding\n\n1.  The effect of aspirin on the risk of stroke may be confounded if the drug is\n    more likely to be prescribed to individuals with heart disease that is both\n    an indication for treatment and a risk factor for the disease. An unmeasured\n    variable, atherosclerosis, is a causal factor for both heart disease and\n    stroke. Such confounding is often called *confounding by indication*.\n2.  The effect of a DNA sequence A on the risk of developing cancer will be\n    confounded if there exists another DNA sequence B that has a causal effect\n    on cancer and is more frequent among people carrying A. This phenomenon is\n    often called *linkage disequilibrium*. A similar bias can occur if the\n    particular causal sequence B is more prevalent in some ethnicities than\n    others, and the study includes a mixture of individuals from different\n    ethnic groups; this is often referred to as *population stratification*.\n3.  Smoking and alcohol consumption are risk factors for several cancers, and\n    they also tend to co-occur, resulting in confounding.\n\n#### Appearances are deceiving\n\nWe can consider the implications of different causal patterns in our analysis.\nThe {{< fa brands r-project >}} package **quartets** provides one set of\nexamples.\n\n::: callout-note\nThe following exposition is from *Causal Inference in R*, chapter 6\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(quartets)\ncausal_quartet |>\n  # hide the dataset names\n  mutate(dataset = as.integer(factor(dataset))) |>\n  group_by(dataset) |>\n  mutate(exposure = scale(exposure), outcome = scale(outcome)) |>\n  ungroup() |>\n  ggplot(aes(exposure, outcome)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~dataset)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week-03_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\nThough the observed associations between exposure and outcome are similar here,\nthere is the presence of a third variable, `covariate`, that affects the causal\nrelationship in different ways. The covariate is acting in different ways in\neach dataset. Our usual way of thinking about a confounder, in terms of a\nvariable that is associated with both outcome and exposure, doesn't quite work\nin distinguishing the causal paths; the respective associations are very\nsimilar.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncausal_quartet |> \n  mutate(dataset = as.integer(factor(dataset))) |> \n  group_by(dataset) |> \n  summarise(exposure = cor(exposure, covariate), outcome = cor(outcome,covariate))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  dataset exposure outcome\n    <int>    <dbl>   <dbl>\n1       1    0.700   0.788\n2       2    0.696   0.783\n3       3    0.696   0.853\n4       4    0.696   0.571\n```\n\n\n:::\n:::\n\n\n\n\n\nWe can even look at the effect of adjusting for the covariate:\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"nrvmomxjpz\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#nrvmomxjpz table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#nrvmomxjpz thead, #nrvmomxjpz tbody, #nrvmomxjpz tfoot, #nrvmomxjpz tr, #nrvmomxjpz td, #nrvmomxjpz th {\n  border-style: none;\n}\n\n#nrvmomxjpz p {\n  margin: 0;\n  padding: 0;\n}\n\n#nrvmomxjpz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 80%;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#nrvmomxjpz .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#nrvmomxjpz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#nrvmomxjpz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#nrvmomxjpz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#nrvmomxjpz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#nrvmomxjpz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#nrvmomxjpz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#nrvmomxjpz .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#nrvmomxjpz .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#nrvmomxjpz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#nrvmomxjpz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#nrvmomxjpz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#nrvmomxjpz .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#nrvmomxjpz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nrvmomxjpz .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#nrvmomxjpz .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#nrvmomxjpz .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#nrvmomxjpz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nrvmomxjpz .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#nrvmomxjpz .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nrvmomxjpz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#nrvmomxjpz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nrvmomxjpz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#nrvmomxjpz .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#nrvmomxjpz .gt_left {\n  text-align: left;\n}\n\n#nrvmomxjpz .gt_center {\n  text-align: center;\n}\n\n#nrvmomxjpz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#nrvmomxjpz .gt_font_normal {\n  font-weight: normal;\n}\n\n#nrvmomxjpz .gt_font_bold {\n  font-weight: bold;\n}\n\n#nrvmomxjpz .gt_font_italic {\n  font-style: italic;\n}\n\n#nrvmomxjpz .gt_super {\n  font-size: 65%;\n}\n\n#nrvmomxjpz .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#nrvmomxjpz .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#nrvmomxjpz .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#nrvmomxjpz .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#nrvmomxjpz .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#nrvmomxjpz .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#nrvmomxjpz .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Dataset\">Dataset</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"ATE not adjusting for Z\">ATE not adjusting for Z</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"ATE adjusting for Z\">ATE adjusting for Z</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Correlation of X and Z\">Correlation of X and Z</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"dataset\" class=\"gt_row gt_right\">1</td>\n<td headers=\"ate_x\" class=\"gt_row gt_right\">1.00</td>\n<td headers=\"ate_xz\" class=\"gt_row gt_right\">0.55</td>\n<td headers=\"cor\" class=\"gt_row gt_right\">0.70</td></tr>\n    <tr><td headers=\"dataset\" class=\"gt_row gt_right\">2</td>\n<td headers=\"ate_x\" class=\"gt_row gt_right\">1.00</td>\n<td headers=\"ate_xz\" class=\"gt_row gt_right\">0.50</td>\n<td headers=\"cor\" class=\"gt_row gt_right\">0.70</td></tr>\n    <tr><td headers=\"dataset\" class=\"gt_row gt_right\">3</td>\n<td headers=\"ate_x\" class=\"gt_row gt_right\">1.00</td>\n<td headers=\"ate_xz\" class=\"gt_row gt_right\">0.00</td>\n<td headers=\"cor\" class=\"gt_row gt_right\">0.70</td></tr>\n    <tr><td headers=\"dataset\" class=\"gt_row gt_right\">4</td>\n<td headers=\"ate_x\" class=\"gt_row gt_right\">1.00</td>\n<td headers=\"ate_xz\" class=\"gt_row gt_right\">0.88</td>\n<td headers=\"cor\" class=\"gt_row gt_right\">0.70</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\nIt turns out that the four datasets have quite different causal structures:\n\n\n\n\n\n::: {#fig-quartet-dag .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![The DAG for dataset 1, where `covariate`  (c) is a collider. We should *not* adjust for `covariate`, which is a descendant of `exposure` (e) and `outcome` (o).](week-03_files/figure-html/fig-quartet-dag-1.png){#fig-quartet-dag-1 width=288}\n:::\n\n::: {.cell-output-display}\n![The DAG for dataset 2, where `covariate` (c) is a confounder. `covariate` is a mutual cause of `exposure` (e) and `outcome` (o), representing a backdoor path, so we *must* adjust for it to get the right answer.](week-03_files/figure-html/fig-quartet-dag-2.png){#fig-quartet-dag-2 width=288}\n:::\n\n::: {.cell-output-display}\n![The DAG for dataset 3, where `covariate` (c) is a mediator. `covariate` is a descendant of `exposure` (e) and a cause of `outcome` (o). The path through `covariate` is the indirect path, and the path through `exposure` is the direct path. We should adjust for `covariate` if we want the direct effect, but not if we want the total effect.](week-03_files/figure-html/fig-quartet-dag-3.png){#fig-quartet-dag-3 width=288}\n:::\n\n::: {.cell-output-display}\n![The DAG for dataset 4, where `covariate` (c) is a collider via M-Bias. Although `covariate` happens before both `outcome` (o) and `exposure` (e), it's still a collider. We should *not* adjust for `covariate`, particularly since we can't control for the bias via `u1` and `u2`, which are unmeasured.](week-03_files/figure-html/fig-quartet-dag-4.png){#fig-quartet-dag-4 width=288}\n:::\n\nThe DAGs for the Causal Quartet\n:::\n\n\n\n\n\nThe DAGs suggest the proper adjustment models for each dataset\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"rfqwfspjwi\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#rfqwfspjwi table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#rfqwfspjwi thead, #rfqwfspjwi tbody, #rfqwfspjwi tfoot, #rfqwfspjwi tr, #rfqwfspjwi td, #rfqwfspjwi th {\n  border-style: none;\n}\n\n#rfqwfspjwi p {\n  margin: 0;\n  padding: 0;\n}\n\n#rfqwfspjwi .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 100%;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#rfqwfspjwi .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#rfqwfspjwi .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#rfqwfspjwi .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#rfqwfspjwi .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#rfqwfspjwi .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#rfqwfspjwi .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#rfqwfspjwi .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#rfqwfspjwi .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#rfqwfspjwi .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#rfqwfspjwi .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#rfqwfspjwi .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#rfqwfspjwi .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#rfqwfspjwi .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#rfqwfspjwi .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rfqwfspjwi .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#rfqwfspjwi .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#rfqwfspjwi .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#rfqwfspjwi .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rfqwfspjwi .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#rfqwfspjwi .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rfqwfspjwi .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#rfqwfspjwi .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rfqwfspjwi .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#rfqwfspjwi .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#rfqwfspjwi .gt_left {\n  text-align: left;\n}\n\n#rfqwfspjwi .gt_center {\n  text-align: center;\n}\n\n#rfqwfspjwi .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#rfqwfspjwi .gt_font_normal {\n  font-weight: normal;\n}\n\n#rfqwfspjwi .gt_font_bold {\n  font-weight: bold;\n}\n\n#rfqwfspjwi .gt_font_italic {\n  font-style: italic;\n}\n\n#rfqwfspjwi .gt_super {\n  font-size: 65%;\n}\n\n#rfqwfspjwi .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#rfqwfspjwi .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#rfqwfspjwi .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#rfqwfspjwi .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#rfqwfspjwi .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#rfqwfspjwi .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#rfqwfspjwi .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Data generating mechanism\">Data generating mechanism</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Correct causal model\">Correct causal model</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Correct causal effect\">Correct causal effect</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Data generating mechanism\" class=\"gt_row gt_left\">(1) Collider</td>\n<td headers=\"Correct causal model\" class=\"gt_row gt_left\">Y ~ X</td>\n<td headers=\"Correct causal effect\" class=\"gt_row gt_left\">1.0</td></tr>\n    <tr><td headers=\"Data generating mechanism\" class=\"gt_row gt_left\">(2) Confounder</td>\n<td headers=\"Correct causal model\" class=\"gt_row gt_left\">Y ~ X ; Z</td>\n<td headers=\"Correct causal effect\" class=\"gt_row gt_left\">0.5</td></tr>\n    <tr><td headers=\"Data generating mechanism\" class=\"gt_row gt_left\">(3) Mediator</td>\n<td headers=\"Correct causal model\" class=\"gt_row gt_left\">Direct effect: Y ~ X ; Z\n  Total Effect: Y ~ X</td>\n<td headers=\"Correct causal effect\" class=\"gt_row gt_left\">Direct effect: 0.0\n  Total effect: 1.0</td></tr>\n    <tr><td headers=\"Data generating mechanism\" class=\"gt_row gt_left\">(4) M-Bias</td>\n<td headers=\"Correct causal model\" class=\"gt_row gt_left\">Y ~ X</td>\n<td headers=\"Correct causal effect\" class=\"gt_row gt_left\">1.0</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\n#### Residual confounding\n\nResidual confounding is often a complication in many observational studies where\ncovariate adjustment to account for measured confounders has been undertaken.\nThis refers to confounding that persists after adjustment, and may be due to\n*unmeasured confounders* or due to *incorrect analysis*.\n\n--------------------------------------------------------------------------------\n\n::: callout-note\n## Pearl's *do*-operator\n\nPearl proposes a *do*-operator to describe causaility. This operator is defined\noperationally as $P(Y | do(X=1))$ is the probability of seeing *Y* when one is\n**made to experience** X=1, rather than passively observing *X*. This is not a\nstraightforward concept, but generally speaking, we can say that we have\nobserved the causal effect of *X* on *Y* if\n\n$$\nP(Y | X) = P(Y | do(X))\n$$\n\nwith inequality here suggesting the presence of confounders, both measured and\nunmeasured.\n\nFeel free to delve further into this in The Book of Why, or Pearl's more\ncomprehensive work, *Causality*.\n:::\n\n--------------------------------------------------------------------------------\n\n## Concept 3: Principles to establish causality\n\nThis appears quite straightforward, but does have some underlying assumptions:\n\n**No interference:**\n\n:   Unit *i*'s potential outcomes do not depend on the outcomes of the other\n    units.\n\n**Consistency:**\n\n:   There are no other versions of the treament, or that we need treatment\n    levels to be well defined\n\n> These assumptions together are called the **Stable Unit Treatment Value\n> Assumption (SUTVA)** (@rubin:1980)\n\nExchangeability\n\n:   We assume that within levels of relevant variables (confounders), exposed\n    and unexposed individuals have the same chance of experiencing any outcome\n    prior to being exposed. This can be interpreted to mean that there is *no\n    unmeasured confounding*\n\nPositivity\n\n:   Each individual has a positive chance of being exposed to every available\n    exposure level. In our earlier example, this means that there is no one who\n    is prohibited from taking ibuprofen, and no one who is required to just take\n    ibuprofen.\n\nThe point of these principles is to enable apples-to-apples comparison, so that\nthe individuals are comparable and can be good proxies for each others'\ncounterfactuals.\n\n::: callout-important\nThere are a nice set of simulations\n[here](https://www.r-causal.org/chapters/03-counterfactuals#causal-assumptions-simulation)\nthat shows what might go wrong in our causal effect estimates if these\nassumptions are violated\n:::\n\nIt is good to remember that these assumptions are, to some extent, idealized and\nsometimes cannot be validated from the data. We would need information outside\nof the empirical data to justify making these assumptions.\n",
    "supporting": [
      "week-03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}